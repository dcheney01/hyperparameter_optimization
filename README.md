# hyperparameter_optimization

This repository is a package that contains code to easily optimize a learned model that can predict the dynamics of a given physical system. 


## External Dependencies
* numpy
* matplotlib
* pytorch
* pytorch_lightning
* ray
* wandb (for logging)
* nempc (Phil Hyatt's work)

## Usage
See the inverted pendulum for a complete example. 
To add a new system to optimize a learned dynamic model you need to create the following folder structure:

|-- hyperparameter_optimization
|   |-- new_dynamic_system
|   |    |-- data 
|   |    +-- ModelDynamics.py
|   |    +-- model_optimize.py
|   |    +-- LearnedModel.py
|   |    +-- Model_nempc.py
|   |    +-- control_test.ipynb


## ModelDynamics.py
This file inherits from the BASE/Model.py file. 

Models that require angle wrapping should define (note: the forward_simulate_dt() function in Model.py uses these arguments, so overwriting forward_simulate_dt is not recommended for models with wrapped angles)

* self.wrapAngle = boolean np array with True value in place of each angle to wrap
* self.wrapRange = tuple specifying (low, high)

It is also recommended that each model contain:

* a visualize() function

Each model should also inherit from Model.py, giving access to several key functions, with descriptions in their docstrings in Model.py. The most useful in general is forward_simulate_dt(), which is the basis for most simulation in rad_models. There are also several functions for getting approximate A, B, and w matrices. These are approximate, so if you want high fidelity, you should overwrite those methods in your model definition.

## model_optimization.py
This file needs to inherit both the BASE/DatasetBaseClass and BASE/LightningModuleBaseClass. Generally the dataset class does not require any additional modification, but the LightningModuleBaseClass will need to implement calculate_metrics() and on_validation_epoch_end() based on the metrics you want to track. 


You also need to have a system_config python dictionary with the following (see ip_optimize.py for data types):
* project_name - wandb project name to log results to
* run_name - specific run within the project
* nn_arch - type of architecture to use (currently supports FNN and LSTM, see BASE/NN_Architectures.py)
* b_size - batch size
* n_hlay - hidden layers, may mean something different based on the nn_arch
* hdim - hidden nodes in each hidden layer
* lr - learning rate
* act_fn - activation function
* loss_fn - loss function
* opt - optimizer
* metric - metric to base the optimization on
* mode - see ray tune, but I've used max and min (if you want to maximize or minimize the metric)
* logmetric1_name - metric that you want to log
* logmetric2_name - metric 2 that you want to log
* n_inputs - number of inputs to the NN Model 
* n_outputs - number of outputs the NN Model has
* accuracy_tolerance - accuracy tolerance to consider a prediction "accurate", see BASE/LightningModuleBaseClass.py 
* num_workers - used for the DataLoader
* generate_new_data - whether or not to generate new data for each sample
* learn_mode - x or xdot, what the model should predict
* dataset_size - how many datapoints to generate
* normalized_data - whether or not to use normalized data
* dt - spacing of datapoints in time
* cpu_num - cpus per sample in the optimization
* gpu_num - gpus per sample in the optimization (can be decimal)
* max_epochs - max epochs for each sample to run in the optimization
* num_samples - number of samples to try in the optimization
* path - path to the code (hyperparam_optimization/ModelCode/) 


## LearnedModel.py
Class that acts in the same way that ModelDynamics.py that can forward propagate the dynamics of the system

## model_nempc.py
File to control the system using NEMPC. You will need to write a cost function that defines the goal of the controller. 

## control_test.ipynb
This is a helpful file to quickly evaluate models generated by the optimization.

## TODO
- Add more architecture types to NN_Architectures
- 

## Authors
Repo originally created by Daniel Cheney

